{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n",
    "Import necessary libraries such as pandas, numpy, librosa, sklearn, matplotlib, and pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Explore the Dataset\n",
    "Load the 30-second and 3-second features datasets using pandas and display the first few rows to understand the structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** df_30_sec has 1000 rows and 60 columns **\n",
      "** df_3_sec has 9990 rows and 60 columns **\n",
      "30-Second Features Dataset:\n",
      "          filename  length  chroma_stft_mean  chroma_stft_var  rms_mean  \\\n",
      "0  blues.00000.wav  661794          0.350088         0.088757  0.130228   \n",
      "1  blues.00001.wav  661794          0.340914         0.094980  0.095948   \n",
      "2  blues.00002.wav  661794          0.363637         0.085275  0.175570   \n",
      "3  blues.00003.wav  661794          0.404785         0.093999  0.141093   \n",
      "4  blues.00004.wav  661794          0.308526         0.087841  0.091529   \n",
      "\n",
      "    rms_var  spectral_centroid_mean  spectral_centroid_var  \\\n",
      "0  0.002827             1784.165850          129774.064525   \n",
      "1  0.002373             1530.176679          375850.073649   \n",
      "2  0.002746             1552.811865          156467.643368   \n",
      "3  0.006346             1070.106615          184355.942417   \n",
      "4  0.002303             1835.004266          343399.939274   \n",
      "\n",
      "   spectral_bandwidth_mean  spectral_bandwidth_var  ...  mfcc16_var  \\\n",
      "0              2002.449060            85882.761315  ...   52.420910   \n",
      "1              2039.036516           213843.755497  ...   55.356403   \n",
      "2              1747.702312            76254.192257  ...   40.598766   \n",
      "3              1596.412872           166441.494769  ...   44.427753   \n",
      "4              1748.172116            88445.209036  ...   86.099236   \n",
      "\n",
      "   mfcc17_mean  mfcc17_var  mfcc18_mean  mfcc18_var  mfcc19_mean  mfcc19_var  \\\n",
      "0    -1.690215   36.524071    -0.408979   41.597103    -2.303523   55.062923   \n",
      "1    -0.731125   60.314529     0.295073   48.120598    -0.283518   51.106190   \n",
      "2    -7.729093   47.639427    -1.816407   52.382141    -3.439720   46.639660   \n",
      "3    -3.319597   50.206673     0.636965   37.319130    -0.619121   37.259739   \n",
      "4    -5.454034   75.269707    -0.916874   53.613918    -4.404827   62.910812   \n",
      "\n",
      "   mfcc20_mean  mfcc20_var  label  \n",
      "0     1.221291   46.936035  blues  \n",
      "1     0.531217   45.786282  blues  \n",
      "2    -2.231258   30.573025  blues  \n",
      "3    -3.407448   31.949339  blues  \n",
      "4   -11.703234   55.195160  blues  \n",
      "\n",
      "[5 rows x 60 columns]\n",
      "\n",
      "3-Second Segments Dataset:\n",
      "            filename  length  chroma_stft_mean  chroma_stft_var  rms_mean  \\\n",
      "0  blues.00000.0.wav   66149          0.335406         0.091048  0.130405   \n",
      "1  blues.00000.1.wav   66149          0.343065         0.086147  0.112699   \n",
      "2  blues.00000.2.wav   66149          0.346815         0.092243  0.132003   \n",
      "3  blues.00000.3.wav   66149          0.363639         0.086856  0.132565   \n",
      "4  blues.00000.4.wav   66149          0.335579         0.088129  0.143289   \n",
      "\n",
      "    rms_var  spectral_centroid_mean  spectral_centroid_var  \\\n",
      "0  0.003521             1773.065032          167541.630869   \n",
      "1  0.001450             1816.693777           90525.690866   \n",
      "2  0.004620             1788.539719          111407.437613   \n",
      "3  0.002448             1655.289045          111952.284517   \n",
      "4  0.001701             1630.656199           79667.267654   \n",
      "\n",
      "   spectral_bandwidth_mean  spectral_bandwidth_var  ...  mfcc16_var  \\\n",
      "0              1972.744388           117335.771563  ...   39.687145   \n",
      "1              2010.051501            65671.875673  ...   64.748276   \n",
      "2              2084.565132            75124.921716  ...   67.336563   \n",
      "3              1960.039988            82913.639269  ...   47.739452   \n",
      "4              1948.503884            60204.020268  ...   30.336359   \n",
      "\n",
      "   mfcc17_mean  mfcc17_var  mfcc18_mean  mfcc18_var  mfcc19_mean  mfcc19_var  \\\n",
      "0    -3.241280   36.488243     0.722209   38.099152    -5.050335   33.618073   \n",
      "1    -6.055294   40.677654     0.159015   51.264091    -2.837699   97.030830   \n",
      "2    -1.768610   28.348579     2.378768   45.717648    -1.938424   53.050835   \n",
      "3    -3.841155   28.337118     1.218588   34.770935    -3.580352   50.836224   \n",
      "4     0.664582   45.880913     1.689446   51.363583    -3.392489   26.738789   \n",
      "\n",
      "   mfcc20_mean  mfcc20_var  label  \n",
      "0    -0.243027   43.771767  blues  \n",
      "1     5.784063   59.943081  blues  \n",
      "2     2.517375   33.105122  blues  \n",
      "3     3.630866   32.023678  blues  \n",
      "4     0.536961   29.146694  blues  \n",
      "\n",
      "[5 rows x 60 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df_30_sec = pd.read_csv('Data/features_30_sec.csv')\n",
    "df_3_sec = pd.read_csv('Data/features_3_sec.csv')\n",
    "\n",
    "# Display the shape and summary of the datasets\n",
    "print(f\"** df_30_sec has {df_30_sec.shape[0]} rows and {df_30_sec.shape[1]} columns **\")\n",
    "df_30_sec.describe()\n",
    "\n",
    "print(f\"** df_3_sec has {df_3_sec.shape[0]} rows and {df_3_sec.shape[1]} columns **\")\n",
    "df_30_sec.describe()\n",
    "\n",
    "# Display the first few rows of the datasets\n",
    "print(\"30-Second Features Dataset:\")\n",
    "print(df_30_sec.head())\n",
    "\n",
    "print(\"\\n3-Second Segments Dataset:\")\n",
    "print(df_3_sec.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "Extract relevant audio features (e.g., MFCCs, spectral contrast, tempo) using librosa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Features: [-1.13619385e+02  1.21553032e+02 -1.91510563e+01  4.23457680e+01\n",
      " -6.37116766e+00  1.86130333e+01 -1.36920605e+01  1.53393784e+01\n",
      " -1.22836170e+01  1.09737759e+01 -8.32240963e+00  8.80678749e+00\n",
      " -3.66580200e+00  1.59876027e+01  1.51024777e+01  1.84584091e+01\n",
      "  1.83631251e+01  1.89187388e+01  1.71902361e+01  3.96675767e+01\n",
      "  8.30663911e-02  1.23046875e+02]\n"
     ]
    }
   ],
   "source": [
    "# Function to extract audio features from a file\n",
    "def extract_features(file_name):\n",
    "    y, sr = librosa.load(file_name, duration=30)\n",
    "\n",
    "    # Extracting MFCCs\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13).T, axis=0)\n",
    "\n",
    "    # Extracting Spectral Contrast\n",
    "    spectral_contrast = np.mean(librosa.feature.spectral_contrast(y=y, sr=sr).T, axis=0)\n",
    "\n",
    "    # Extracting Zero-Crossing Rate\n",
    "    zero_crossing_rate = np.mean(librosa.feature.zero_crossing_rate(y).T, axis=0)\n",
    "\n",
    "    # Extracting Tempo\n",
    "    tempo, _ = librosa.beat.beat_track(y=y, sr=sr)\n",
    "\n",
    "    # Combining all features into a single array\n",
    "    features = np.hstack([mfccs, spectral_contrast, zero_crossing_rate, tempo])\n",
    "\n",
    "    return features\n",
    "\n",
    "example_features = extract_features('Data/genres_original/blues/blues.00000.wav')\n",
    "print(\"Extracted Features:\", example_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test Split\n",
    "Split the dataset into training and testing sets using train_test_split from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30-Second Features Dataset:\n",
      "Training set shape: (800, 58) (800,)\n",
      "Testing set shape: (200, 58) (200,)\n",
      "\n",
      "3-Second Segments Dataset:\n",
      "Training set shape: (7992, 58) (7992,)\n",
      "Testing set shape: (1998, 58) (1998,)\n"
     ]
    }
   ],
   "source": [
    "# Define the features (X) and labels (y) for the 30-second features dataset\n",
    "X_30_sec = df_30_sec.drop(columns=['filename', 'label'])\n",
    "y_30_sec = df_30_sec['label']\n",
    "\n",
    "# Define the features (X) and labels (y) for the 3-second segments dataset\n",
    "X_3_sec = df_3_sec.drop(columns=['filename', 'label'])\n",
    "y_3_sec = df_3_sec['label']\n",
    "\n",
    "# Split the 30-second features dataset into training and testing sets\n",
    "X_train_30_sec, X_test_30_sec, y_train_30_sec, y_test_30_sec = train_test_split(X_30_sec, y_30_sec, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the 3-second segments dataset into training and testing sets\n",
    "X_train_3_sec, X_test_3_sec, y_train_3_sec, y_test_3_sec = train_test_split(X_3_sec, y_3_sec, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shapes of the resulting datasets\n",
    "print(\"30-Second Features Dataset:\")\n",
    "print(\"Training set shape:\", X_train_30_sec.shape, y_train_30_sec.shape)\n",
    "print(\"Testing set shape:\", X_test_30_sec.shape, y_test_30_sec.shape)\n",
    "\n",
    "print(\"\\n3-Second Segments Dataset:\")\n",
    "print(\"Training set shape:\", X_train_3_sec.shape, y_train_3_sec.shape)\n",
    "print(\"Testing set shape:\", X_test_3_sec.shape, y_test_3_sec.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Random Forest Classifier\n",
    "Train a Random Forest Classifier on the training data. Random forests are less prone to overfitting due to their ensemble nature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30-Second Features Dataset:\n",
      "Accuracy: 0.76\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       blues       0.64      0.90      0.75        20\n",
      "   classical       1.00      1.00      1.00        13\n",
      "     country       0.76      0.59      0.67        27\n",
      "       disco       0.75      0.71      0.73        21\n",
      "      hiphop       0.59      0.87      0.70        15\n",
      "        jazz       0.95      0.91      0.93        22\n",
      "       metal       0.85      0.92      0.88        25\n",
      "         pop       0.79      0.85      0.81        13\n",
      "      reggae       0.78      0.61      0.68        23\n",
      "        rock       0.56      0.43      0.49        21\n",
      "\n",
      "    accuracy                           0.76       200\n",
      "   macro avg       0.77      0.78      0.77       200\n",
      "weighted avg       0.77      0.76      0.76       200\n",
      "\n",
      "\n",
      "3-Second Segments Dataset:\n",
      "Accuracy: 0.8813813813813813\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       blues       0.86      0.85      0.85       208\n",
      "   classical       0.93      0.98      0.96       203\n",
      "     country       0.77      0.83      0.80       186\n",
      "       disco       0.87      0.86      0.87       199\n",
      "      hiphop       0.93      0.88      0.90       218\n",
      "        jazz       0.85      0.93      0.89       192\n",
      "       metal       0.88      0.97      0.92       204\n",
      "         pop       0.93      0.94      0.93       180\n",
      "      reggae       0.91      0.88      0.90       211\n",
      "        rock       0.88      0.70      0.78       197\n",
      "\n",
      "    accuracy                           0.88      1998\n",
      "   macro avg       0.88      0.88      0.88      1998\n",
      "weighted avg       0.88      0.88      0.88      1998\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Encode the target labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_30_sec_encoded = label_encoder.fit_transform(y_train_30_sec)\n",
    "y_test_30_sec_encoded = label_encoder.transform(y_test_30_sec)\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the classifier on the 30-second features dataset\n",
    "rf_classifier.fit(X_train_30_sec, y_train_30_sec_encoded)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_30_sec = rf_classifier.predict(X_test_30_sec)\n",
    "\n",
    "# Decode the predicted labels back to original\n",
    "y_pred_30_sec_decoded = label_encoder.inverse_transform(y_pred_30_sec)\n",
    "\n",
    "# Evaluate the model using original labels\n",
    "accuracy_30_sec = accuracy_score(y_test_30_sec, y_pred_30_sec_decoded)\n",
    "classification_report_30_sec = classification_report(y_test_30_sec, y_pred_30_sec_decoded)\n",
    "\n",
    "print(\"30-Second Features Dataset:\")\n",
    "print(\"Accuracy:\", accuracy_30_sec)\n",
    "print(\"Classification Report:\\n\", classification_report_30_sec)\n",
    "\n",
    "# Encode the target labels for the 3-second segments dataset\n",
    "y_train_3_sec_encoded = label_encoder.fit_transform(y_train_3_sec)\n",
    "y_test_3_sec_encoded = label_encoder.transform(y_test_3_sec)\n",
    "\n",
    "# Train the classifier on the 3-second segments dataset\n",
    "rf_classifier.fit(X_train_3_sec, y_train_3_sec_encoded)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_3_sec = rf_classifier.predict(X_test_3_sec)\n",
    "\n",
    "# Decode the predicted labels back to original\n",
    "y_pred_3_sec_decoded = label_encoder.inverse_transform(y_pred_3_sec)\n",
    "\n",
    "# Evaluate the model using original labels\n",
    "accuracy_3_sec = accuracy_score(y_test_3_sec, y_pred_3_sec_decoded)\n",
    "classification_report_3_sec = classification_report(y_test_3_sec, y_pred_3_sec_decoded)\n",
    "\n",
    "print(\"\\n3-Second Segments Dataset:\")\n",
    "print(\"Accuracy:\", accuracy_3_sec)\n",
    "print(\"Classification Report:\\n\", classification_report_3_sec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the Model\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
